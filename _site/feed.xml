<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="http://localhost:4000//assets/xslt/rss.xslt" ?>
<?xml-stylesheet type="text/css" href="http://localhost:4000//assets/css/rss.css" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Kimberly Fessel Blog</title>
		<description>Kimberly Fessel is a Senior Data Scientist at Metis. Her enthusiasm for data storytelling often leads her toward better math, better visuals, and better science!</description>
		<link>http://localhost:4000//</link>
		<atom:link href="http://localhost:4000//feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>Python for Data Science: An Interview with Course Report</title>
				<link>http://localhost:4000//python/course-report-python-ds/</link>
				<pubDate>Tue, 15 Sep 2020 00:00:00 -0400</pubDate>
				<description>&lt;!--more--&gt;

&lt;p&gt;In a recent interview with &lt;a href=&quot;https://www.coursereport.com/&quot;&gt;Course Report&lt;/a&gt;, I discussed the basics of Python and how Python is used for data science.  Python serves as an all-purpose programming language, so data scientists, engineers, analysts, and web developers alike utilize Python to build end-to-end projects, ready for launch into production.  Python also has incredibly simple syntax, which makes it a great first programming language for beginners.  We chat about these topics and many more in the video!&lt;/p&gt;

&lt;p&gt;You can also check out a write up of our interview on the &lt;a href=&quot;https://www.coursereport.com/blog/how-is-python-used-for-data-science-metis&quot;&gt;Course Report blog&lt;/a&gt;.&lt;/p&gt;

</description>
				<guid isPermaLink="true">http://localhost:4000//python/course-report-python-ds/</guid>
			</item>
		
			<item>
				<title>Delorean for Datetime Manipulation</title>
				<link>http://localhost:4000//python/datetime/delorean-datetime-manipulation/</link>
				<pubDate>Sat, 25 Jul 2020 00:00:00 -0400</pubDate>
				<description>&lt;!--more--&gt;

&lt;p&gt;This year’s pandemic necessitated different conference formats for data science professionals.  The organizers of PyOhio decided to ask speakers to create 5- or 10-minute pre-recorded talks to be streamed continuously while participants discussed the content in a live chat session.  The format was a success!  And I am proud to have created this video all about the Python library Delorean.&lt;/p&gt;

&lt;p&gt;Delorean makes working with datetimes in Python much less of a burden.  Its simple syntax allows users: to do datetime arithmetic, to handle time zone shifts, to convert datetimes into human language like “3 days ago,” and to generate equally spaced datetime intervals.&lt;/p&gt;

&lt;p&gt;Check out my video for a look at Delorean (along with many, many &lt;em&gt;Back to the Future&lt;/em&gt; references) or watch the &lt;a href=&quot;https://www.youtube.com/watch?v=OGmzRIgDgOY&amp;amp;list=PL2k6bbM_wgjtGSzPXzUzP3AfVO-o4imbB&quot;&gt;full PyOhio 2020 conference playlist on YouTube&lt;/a&gt;.&lt;/p&gt;

</description>
				<guid isPermaLink="true">http://localhost:4000//python/datetime/delorean-datetime-manipulation/</guid>
			</item>
		
			<item>
				<title>Measuring Statistical Dispersion with the Gini Coefficient</title>
				<link>http://localhost:4000//mathematics/applications/gini-use-cases/</link>
				<pubDate>Fri, 05 Jun 2020 00:00:00 -0400</pubDate>
				<description>&lt;center&gt;
&lt;iframe width=&quot;900&quot; height=&quot;550&quot; src=&quot;//www.youtube.com/embed/nFbAnwIYle4&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/center&gt;

&lt;hr /&gt;

&lt;p&gt;If you work with data long enough, you are bound to discover that a dataset’s mean rarely–if ever–tells you the full data story.  As a simple example, each of the following groups of people have the same &lt;strong&gt;average pay&lt;/strong&gt; of $100:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;100 people who make $100 each&lt;/li&gt;
  &lt;li&gt;50 people who make $150 each and 50 people who make $50&lt;/li&gt;
  &lt;li&gt;1 person who makes $10,000 and 99 people who make nothing&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The primary difference, of course, is the way that money is distributed among the people, also known as the &lt;a href=&quot;https://en.wikipedia.org/wiki/Statistical_dispersion&quot;&gt;statistical dispersion&lt;/a&gt;.  Perhaps the most popular measurement of statistical dispersion is standard deviation or variance; however, you can leverage other metrics, such as the Gini coefficient, to obtain a new perspective.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Gini_coefficient&quot;&gt;The Gini coefficient&lt;/a&gt;, also known as the Gini index or the Gini ratio, was introduced in 1912 by Italian statistician and sociologist Corrado Gini.  Analysts have historically used this value to study income or wealth distributions; in fact, despite being developed over 100 years ago, &lt;a href=&quot;https://www.bbc.com/news/blogs-magazine-monitor-31847943&quot;&gt;the United Nations still uses the Gini coefficient&lt;/a&gt; to understand monetary inequities in their annual ranking of nations. But the Gini coefficient may be utilized much more broadly! After a more thorough mathematical explanation, let’s apply the Gini coefficient to a few non-standard use cases that do not involve international economies: baby names and healthcare pricing.&lt;/p&gt;

&lt;h2 id=&quot;defining-gini&quot;&gt;Defining Gini&lt;/h2&gt;

&lt;p&gt;The first step in understanding the Gini coefficient requires a discussion about the Lorenz curve, a graph developed by Max Lorenz for visualizing income or wealth distribution.  To trace out the Lorenz curve, begin by taking the incomes of a population and sorting them from smallest to largest.  Then build a line plot where the \(x\)-values represent the percentage of people seen thus far and the \(y\)-values represent the cumulative proportion of wealth attributed to this percentage of people.  For example, if the poorest 30% of the population holds 10% of a population’s wealth, the curve should pass through the scaled \(x,y\) coordinates (0.3, 0.1).  Note also that if wealth is distributed evenly among all members of a population, the Lorenz curve follows a straight line, \(x=y\).  See the figure below for an illustration of a hypothetical Lorenz curve along with the line of equality.&lt;/p&gt;

&lt;div class=&quot;row&quot;&gt;
  &lt;div class=&quot;large-6 columns&quot;&gt;
      &lt;img src=&quot;https://kimfetti.github.io/images/gini_explanation.png&quot; alt=&quot;The areas surrounding the Lorenz curve define the Gini coefficient: A/(A+B)&quot; width=&quot;350&quot; /&gt;
  &lt;/div&gt;
  &lt;div class=&quot;large-6 columns&quot;&gt;
      &lt;img src=&quot;https://kimfetti.github.io/images/gini_animation.gif&quot; alt=&quot;The Gini coefficient increases as the inequality gap widens.&quot; width=&quot;350&quot; /&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;The Gini coefficient measures how much a population’s Lorenz curve deviates from perfect equality or how much a set of data diverges from equal values.  The Gini coefficient typically ranges from zero to one&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;, where&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;zero represents perfect equality &lt;em&gt;(e.g. everyone has an equal amount)&lt;/em&gt; and&lt;/li&gt;
  &lt;li&gt;one represents near perfect inequality &lt;em&gt;(e.g. one person has all the money)&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For all situations in between, the Gini coefficient \(G\) is defined as
\[G = \frac{A}{A + B}\]
where \(A\) signifies the region enclosed between the line of perfect equality and the Lorenz curve, as indicated in the figure above, while \(A + B\) represents the total triangular area.&lt;/p&gt;

&lt;p&gt;Each of the three situations discussed in the introduction produce an average of $100 per person. The Gini coefficient, however, varies greatly for each scenario as seen in the figure below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://kimfetti.github.io/images/gini_compare.png&quot; alt=&quot;Gini coefficient increases with wealth inequality.&quot; width=&quot;1000&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;gini-in-python&quot;&gt;Gini in Python&lt;/h2&gt;

&lt;p&gt;To calculate a dataset’s Gini coefficient with Python, you have the option of computing the shaded area \(A\) with something like &lt;code class=&quot;highlighter-rouge&quot;&gt;scipy&lt;/code&gt;’s &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.quad.html&quot;&gt;quadrature&lt;/a&gt; routine.  If this style of numerical integration proves slow or too complicated for applications at scale, you can utilize an alternative, &lt;a href=&quot;https://en.wikipedia.org/wiki/Gini_coefficient#Definition&quot;&gt;equivalent definition of the Gini coefficient&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;The Gini coefficient may also be expressed as half of the data’s &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_absolute_difference#Relative_mean_absolute_difference&quot;&gt;relative mean absolute difference&lt;/a&gt;, a normalized form of the average absolute difference among all pairs of observations in the dataset. 
\[ G = \frac{\sum\limits_i \sum\limits_j |x_i - x_j|}{2\sum\limits_i\sum\limits_j x_j}\]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The calculation simplifies further if the data consist of only positive values as it becomes &lt;a href=&quot;https://www.statsdirect.com/help/default.htm#nonparametric_methods/gini.htm&quot;&gt;unnecessary to evaluate all possible pairs&lt;/a&gt;.  Sorting the datapoints in ascending order and assigning a positional index \(i\) yields
\[G = \frac{\sum\limits_i (2i - n - 1)x_i}{n\sum\limits_i x_i}, \]
which is even speedier to compute.&lt;/p&gt;

&lt;p&gt;The best Python implementation of the Gini coefficient that I’ve found comes from &lt;a href=&quot;https://github.com/oliviaguest/gini/blob/master/gini.py&quot;&gt;Olivia Guest&lt;/a&gt;. I will subsequently leverage her vectorized &lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt; routine to calculate Gini in the case studies that follow.&lt;/p&gt;

&lt;h2 id=&quot;case-1-baby-names&quot;&gt;Case #1: Baby Names&lt;/h2&gt;

&lt;p&gt;So far we have mostly addressed the Gini coefficient in the context of its original field of economics.  This metric generalizes, however, to provide insight whenever statistical dispersion plays a critical role.  I will now illustrate two atypical applications to demonstrate how using the Gini coefficient augments the workflow of exploratory data analysis.&lt;/p&gt;

&lt;p&gt;The Social Security Administration of the United States (SSA) &lt;a href=&quot;https://www.ssa.gov/oact/babynames/limits.html&quot;&gt;hosts public records&lt;/a&gt; on the names given to US babies for research purposes.  Aggregating these data for children born since 1950, I discovered that 18 out of the top 20 most popular names more commonly associate with male children.  So where are the females?&lt;/p&gt;

&lt;center&gt;
&lt;img src=&quot;https://kimfetti.github.io/images/popular_names.png&quot; alt=&quot;Most popular names given to US babies since 1950&quot; width=&quot;500&quot; /&gt;
&lt;/center&gt;

&lt;p&gt;Slightly &lt;a href=&quot;https://www.npr.org/sections/health-shots/2015/03/30/396384911/why-are-more-baby-boys-born-than-girls&quot;&gt;more male babies are actually born each year&lt;/a&gt;, and certainly more male babies have been registered with the SSA (53% male vs 47% female); nonetheless, I was still surprised to see such a large proportion of male names in my quick popularity chart. Digging into the data further, I found that even though fewer females appear in the data, there have been consistently more unique female names each year.&lt;/p&gt;

&lt;center&gt;
&lt;img src=&quot;https://kimfetti.github.io/images/unique_names.png&quot; alt=&quot;Number of unique names for male and female babies since 1950&quot; width=&quot;700&quot; /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Statistical dispersion appears to play a significant role.  To put it back in financial terms, some male names like the ones on my top 20 list are just extremely “wealthy.” (The most popular name, “Michael,” accounts for over 3% of all male children born since 1950.)   These ultra-popular masculine names likely pass down from generation to generation.  Females babies, on the other hand, are distributed more widely across a variety of names, so extra names share in the “wealth” of female children.  We can verify this theory by returning to the Gini coefficient.&lt;/p&gt;

&lt;p&gt;Consider how female children disperse across each name.  Some names in the dataset account for only 5 babies&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; since 1950, while “Jennifer” represents nearly 1.5 million individuals.  Tallying up all females born with each name since 1950 and sorting the names from least to most popular, we find the Gini coefficient to be 0.96, implying a huge disparity in the most popular versus the most unique names.&lt;/p&gt;

&lt;p&gt;Male names exhibit a very similar Lorenz curve but with a little more skew, registering a Gini coefficient of 0.97. The difference between male and female coefficients appears insignificant, but consider an alternative viewpoint.  Instead of aggregating across time, calculate a yearly Gini coefficient for each gender.  Plotting both the female and male Gini coefficients for each year since 1950 demonstrates a clear and persistent pattern where the male coefficient presents consistently higher.&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;  Thus male names experience more statistical dispersion than female monikers.   Also of note, the Gini values for both genders have ticked downward since the 1990s, indicating a trending preference toward more diverse naming conventions.&lt;/p&gt;

&lt;center&gt;
&lt;img src=&quot;https://kimfetti.github.io/images/gini_names.png&quot; alt=&quot;The male Gini coefficient tracks consistently higher throughout time&quot; width=&quot;700&quot; /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;In a final look at this dataset, let’s examine popularity trends for individual names over time.  Now utilize Gini by grouping the female data by name and calculating the Gini coefficient as it pertains to yearly frequencies; that is, for any given name, sort each year of the dataset by that name’s least to most popular year in order to compute Gini.  Names with lower Gini coefficients demonstrate similar levels of popularity throughout the entire time span, while higher coefficients imply uneven popularity levels.  The figure below compares popularity trends for the names “Scarlett” and “Miriam.”  Both names represent about 60,000 female babies in the dataset; however, the sharp increase in babies named “Scarlett” generates a large Gini coefficient while “Miriam” sees a low Gini value since the name has consistently been given to roughly 1,000 babies every year since 1950.&lt;/p&gt;

&lt;center&gt;
&lt;img src=&quot;https://kimfetti.github.io/images/scarlett_vs_miriam.png&quot; alt=&quot;The popularity of female names Miriam and Scarlett over time with Gini coeffients&quot; width=&quot;900&quot; /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;case-2-healthcare-prices&quot;&gt;Case #2: Healthcare Prices&lt;/h2&gt;

&lt;p&gt;Now shift to &lt;a href=&quot;https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/Medicare-Provider-Charge-Data/Inpatient2017&quot;&gt;this 2017 healthcare pricing dataset&lt;/a&gt; hosted by the Centers for Medicare and Medicaid Services, a federal agency of the United States.  These data, aggregated as procedural averages for individual hospitals, include the charges and eventual payments for over 500 separate inpatient procedures for Medicare patients.  I applied Gini coefficient calculations to determine which, if any, procedures require better billing standardization.  The underlying basis for my analysis boils down to this: the higher the Gini coefficient, the greater the disparity in what different hospitals charge for a given procedure.  Procedures with large Gini values could then necessitate regulation or more transparent cost details.&lt;/p&gt;

&lt;p&gt;The procedure, or diagnosis related group (DRG), with the highest Gini coefficient in this dataset&lt;sup id=&quot;fnref:4&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt; is labeled as, “Alcohol/Drug Abuse or Dependency w Rehabilitation Therapy.”  This perhaps elicits little surprise given that rehabilitation therapies vary widely both in terms of treatment length and illness severity; we probably expect a wide range in what assorted hospitals charge.  In fact, all diagnoses with the largest Gini coefficients, such as coagulation disorders and psychoses, can vary in severity.  Procedural charges that show the most uniformity among the hospitals, on the other hand, mostly describe one-time cardiac events such as value replacement, percutaneous surgeries, or observation for chest pain.&lt;/p&gt;

&lt;center&gt;
&lt;table width=&quot;800&quot;&gt;
  &lt;caption&gt;Gini coefficients among average hospital charges per diagnosis related group (DRG)&lt;/caption&gt;
  &lt;colgroup&gt;
    &lt;col span=&quot;1&quot; style=&quot;width: 50%;&quot; /&gt;
    &lt;col span=&quot;1&quot; style=&quot;width: 50%;&quot; /&gt;
  &lt;/colgroup&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;center&gt;Highest Gini&lt;/center&gt;&lt;/th&gt;
      &lt;th&gt;&lt;center&gt;Lowest Gini&lt;/center&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Alcohol/Drug Abuse or Dependence w Rehabilitation Therapy&lt;/td&gt;
      &lt;td&gt;Aortic and Heart Assist Procedures except Pulsation Balloon w MCC&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Coagulation Disorders&lt;/td&gt;
      &lt;td&gt;Angina Pectoris&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Alcohol/Drug Abuse or Dependence, Left AMA&lt;/td&gt;
      &lt;td&gt;Cardiac Valve &amp;amp; Oth Maj Cardiothoracic Proc w/o Card Cath w/o CC/MCC&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Psychoses&lt;/td&gt;
      &lt;td&gt;Heart Transplant or Implant of Heart Assist System w MCC&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Other Respiratory System Diagnoses w MCC&lt;/td&gt;
      &lt;td&gt;Perc Cardiovasc Proc w/o Coronary Artery Stent w/o MCC&lt;/td&gt;
    &lt;/tr&gt;
   &lt;/tbody&gt;
&lt;/table&gt;
&lt;/center&gt;

&lt;p&gt;So what about billing regulation?  Do we need more safeguards in place to be sure hospitals are charging similar amounts for similar procedures?  Well, more cost transparency certainly doesn’t hurt, especially for treatments that range in duration or intensity, but let’s go back to the dataset.  In addition to the information about the amounts hospitals charge, the data also contain &lt;a href=&quot;https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/Medicare-Provider-Charge-Data/Downloads/Inpatient_Outpatient_FAQ.pdf&quot;&gt;the total payments that the hospitals actually received&lt;/a&gt;.  Applying the same type of analysis to the payments received yields much lower Gini values.  In fact, the Gini coefficient is lower for the average payments received than the hospital charges, for &lt;em&gt;every single procedure&lt;/em&gt;.  This curious insight signals that the contracts in place for Medicare payments &lt;em&gt;already&lt;/em&gt; do quite a lot to moderate and regularize procedural costs.&lt;sup id=&quot;fnref:5&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;center&gt;
&lt;img src=&quot;https://kimfetti.github.io/images/gini_health.png&quot; alt=&quot;Comparison of Gini coeffients for total payments vs hospital charges&quot; width=&quot;600&quot; /&gt;
&lt;/center&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The Gini coefficient continues to provide insight over 100 years after its inception.  As a good general-purpose measure of statistical dispersion, Gini can be used broadly to explore and understand data from nearly any discipline.  Currently, the most popular metric for understanding data spread is likely standard deviation; however, there are &lt;a href=&quot;https://stats.stackexchange.com/questions/210829/difference-is-summary-statistics-gini-coefficient-and-standard-deviation/211595&quot;&gt;several key differences&lt;/a&gt; between standard deviation and the Gini coefficient.  Firstly, standard deviation retains the scale of your data.  You report the standard deviation of US incomes in dollars, while you might give the standard deviation of temperatures in degrees Celsius. The Gini coefficient, however, has no measurement unit, also called scale invariance. Secondly, standard deviation is unbounded in that it can be any non-negative value, but Gini typically ranges between zero and one.  Gini’s scale invariance and strict bounds make comparing statistical dispersion between two dissimilar data sources much easier.  Lastly, standard deviation and the Gini coefficient judge statistical dispersion through different lenses.  Gini reaches its maximum value for a non-negative dataset if it contains one positive and the rest zeros.  Standard deviation reaches its maximum if half the data live at the extreme maximum and the other half register at the extreme minimum.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.scientificamerican.com/article/ask-gini/&quot;&gt;Certain limitations&lt;/a&gt; apply to the Gini coefficient despite its many benefits.  Like other summary statistics, Gini condenses information thereby losing the granularity of the original dataset.  Gini is also many-to-one, which means various different distributions map to the same coefficient.  The Gini coefficient proves to be quite sensitive to outliers such that a singular extreme datapoint (large or small) can increase Gini dramatically.  Yet, economists have also criticized the Gini coefficient for being &lt;a href=&quot;https://www.bbc.com/news/blogs-magazine-monitor-31847943&quot;&gt;undersensitive to wealth changes in upper and lower echelons&lt;/a&gt;.  Researchers have go on to introduce several alternative metrics to study different aspects of income inequality, such as the &lt;a href=&quot;https://en.wikipedia.org/wiki/Income_inequality_metrics#Palma_ratio&quot;&gt;Palma ratio&lt;/a&gt;, which explicitly captures financial fluctuations for the richest 10% and the poorest 40% of a population.&lt;/p&gt;

&lt;p&gt;No matter which metric you choose to understand statistical dispersion, building data intuition certainly goes beyond simple estimates of the mean or median.  The Gini coefficient, long since popular in the field of economics, provides excellent insight about the spread of data regardless of your chosen subject area. As demonstrated in this post, Gini could be tracked over time, calculated for specific segments of your data, or used to detect processes requiring better price standardization.  Its applications are limitless, and it might just be the missing component of your EDA toolkit.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/kimfetti/Blog/blob/master/gini_coefficient.ipynb&quot;&gt;Check out this code on GitHub!&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;The Gini coefficient is strictly non-negative, \(G \geq 0\), as long as the mean of the data is assumed positive.  Gini can theoretically be greater than one if some data values are negative, which occurs in the context of wealth if some people contribute negatively in the form of debts owed. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;The Social Security Administration does not include names that are given to fewer than 5 babies per gender per state due to privacy reasons; therefore, five children for one given female name since 1950 signifies the absolute minimum allowed. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;The Gini values displayed in the yearly figure are less than the aggregate because popular names tend to stay popular year after year thus bolstering naming inequality and increasing the Gini coefficient. &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot;&gt;
      &lt;p&gt;Some diagnosis related groups (DRGs) occur at as few as one hospital for the entire year.  I have filtered the dataset down to procedures that are documented by at least 50 hospitals to avoid high variance issues. &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot;&gt;
      &lt;p&gt;The payments hospitals receive are strictly less than the amounts they charge. Decreasing a dataset’s mean while holding its standard deviation fixed &lt;a href=&quot;https://repository.upenn.edu/gse_grad_pubs/6/&quot;&gt;actually &lt;em&gt;increases&lt;/em&gt; the Gini coefficient&lt;/a&gt;.  Here we observe just the opposite effect so statistical dispersion must be lessened in the payments received. &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
				<guid isPermaLink="true">http://localhost:4000//mathematics/applications/gini-use-cases/</guid>
			</item>
		
			<item>
				<title>Web Scraping in Python: Real Python Podcast</title>
				<link>http://localhost:4000//data/web%20scraping/realpython-podcast-web-scraping/</link>
				<pubDate>Fri, 05 Jun 2020 00:00:00 -0400</pubDate>
				<description>&lt;!--more--&gt;

&lt;p&gt;I recently sat down with Christopher Bailey at the Real Python Podcast to discuss web scraping as well as my &lt;a href=&quot;https://www.youtube.com/watch?v=RUQWPJ1T6Zc&quot;&gt;PyCon 2020 tutorial&lt;/a&gt;: “It’s Officially Legal so Let’s Scrape the Web.”  In this podcast we talk about web scraping tools and techniques, HTML basics and data cleaning, as well as a recent change to the legal landscape regarding scraping.&lt;/p&gt;

&lt;p&gt;Check out the YouTube video above or listen to the podcast at &lt;a href=&quot;https://realpython.com/podcasts/rpp/12/&quot;&gt;Real Python&lt;/a&gt;.&lt;/p&gt;

</description>
				<guid isPermaLink="true">http://localhost:4000//data/web%20scraping/realpython-podcast-web-scraping/</guid>
			</item>
		
			<item>
				<title>Let's Scrape the Web: PyCon 2020 Video Tutorial</title>
				<link>http://localhost:4000//data/web%20scraping/python-web-scraping/</link>
				<pubDate>Mon, 04 May 2020 00:00:00 -0400</pubDate>
				<description>&lt;!--more--&gt;

&lt;p&gt;Web scraping empowers you to write computer programs to collect data from websites automatically and recent legal rulings support your right to do so.  This tutorial covers the breadth and depth of web scraping: from HTML basics through pipeline methods to compile entire datasets.  My video provides step-by-step instructions on utilizing Python libraries like &lt;code class=&quot;highlighter-rouge&quot;&gt;requests&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;BeautifulSoup&lt;/code&gt; as well as links to supplementary tutorial resources in the form of Google Colab or Jupyter notebooks.&lt;/p&gt;

&lt;p&gt;Check out the supplementary materials via Google Colab (&lt;a href=&quot;https://bit.ly/pycon2020_scrapingbasics&quot;&gt;Scraping Basics&lt;/a&gt; and &lt;a href=&quot;https://bit.ly/pycon2020_scrapingwiki&quot;&gt;Scraping Wikipedia&lt;/a&gt;) or on &lt;a href=&quot;https://github.com/kimfetti/Conferences/tree/master/PyCon_2020&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;

</description>
				<guid isPermaLink="true">http://localhost:4000//data/web%20scraping/python-web-scraping/</guid>
			</item>
		
			<item>
				<title>Level Up: spaCy NLP for the Win</title>
				<link>http://localhost:4000//nlp/spacy-for-the-win/</link>
				<pubDate>Fri, 21 Feb 2020 00:00:00 -0500</pubDate>
				<description>&lt;!--more--&gt;

&lt;p&gt;Natural language processing (NLP) is a branch of artificial intelligence in which computers extract information from written or spoken human language.  This field has experienced a massive rise in popularity over the years, not only among academic communities but also in industry settings. Because unstructured text makes up so much of the data we collect today (e.g. emails, text messages, and even this blog post), many practitioners regularly use NLP at the workplace and require straightforward tools to reliably parse through substantial amounts of documents.  The open-source library spaCy meets these exact demands by processing text quickly and accurately, all within a simplified framework.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://explosion.ai/blog/introducing-spacy&quot;&gt;Released in 2015&lt;/a&gt;, spaCy was initially created to help small businesses better leverage NLP.  Its practical design offers users a streamlined approach for accomplishing necessary NLP tasks, and it assumes a more pragmatic stance toward NLP than traditional libraries like NLTK, which were developed with a more research-focused, exploratory intention.  spaCy can be quite flexible, however, as it allows more experienced users the option of customizing just about any of its tools.  spaCy is considered a Python package, but the “Cy” in spaCy indicates that Cython powers many of the underlining computations.  This makes spaCy incredibly fast, even for more complicated processes.  I will illustrate a selection of spaCy’s core functionality in this post and will end by implementing these techniques on sample restaurant reviews.&lt;/p&gt;

&lt;p&gt;Please continue to the &lt;a href=&quot;https://opendatascience.com/level-up-spacy-nlp-for-the-win/&quot;&gt;ODSC blog&lt;/a&gt; to read my full post covering this introduction to spaCy.&lt;/p&gt;

</description>
				<guid isPermaLink="true">http://localhost:4000//nlp/spacy-for-the-win/</guid>
			</item>
		
			<item>
				<title>Math for Data Science: An Interview with Course Report</title>
				<link>http://localhost:4000//mathematics/course-report-math-ds/</link>
				<pubDate>Mon, 17 Feb 2020 00:00:00 -0500</pubDate>
				<description>&lt;!--more--&gt;

&lt;p&gt;I recently sat down with &lt;a href=&quot;https://www.coursereport.com/&quot;&gt;Course Report&lt;/a&gt; to discuss the math needed to become a data scientist.  Blending coding skills with mathematics lies at the heart of data science, so understanding fundamental math concepts is critical for a successful career within the field.  Linear algebra, calculus, probability, and statistics are the four math disciplines that fuel the bulk of data science.  In this interview, I discuss the role each topic plays in data science; I also work through an example problem from all four subjects.&lt;/p&gt;

&lt;p&gt;Please continue to the &lt;a href=&quot;https://www.coursereport.com/blog/math-for-data-science-with-metis&quot;&gt;Course Report blog&lt;/a&gt; for a write-up of the interview.&lt;/p&gt;

&lt;!--
image:
    thumb: CourseReport_Thumb.png
    homepage: CourseReport_Feb2020.png
    title: CourseReport_Feb2020.png
    caption: &quot;Photo by CP. Image constructed by Course Report.&quot;
    caption_url: &quot;https://www.coursereport.com/&quot;
--&gt;
</description>
				<guid isPermaLink="true">http://localhost:4000//mathematics/course-report-math-ds/</guid>
			</item>
		
			<item>
				<title>Down and Up: A Puzzle Illustrated with D3.js</title>
				<link>http://localhost:4000//visualizations/puzzles/down-and-up/</link>
				<pubDate>Sun, 05 Jan 2020 00:00:00 -0500</pubDate>
				<description>&lt;head&gt;

    &lt;script src=&quot;https://d3js.org/d3.v4.min.js&quot;&gt;&lt;/script&gt;

    &lt;!--Multiple button functions--&gt;
    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/d3/4.3.0/d3.js&quot;&gt;&lt;/script&gt;  
    
    &lt;script src=&quot;https://ajax.googleapis.com/ajax/libs/jquery/1.6.1/jquery.min.js&quot;&gt;&lt;/script&gt;


    &lt;style&gt; 

        input {
          border: none;
          color: white;
          padding: 8px 16px;
          margin: 4px 2px;
          cursor: pointer;
        }
        
        input[name=paintButton] {
          background-color: #271B77;
          font-weight: bold;
        }

        input[name=danceButton] {
          background-color: #6BA450;
          font-weight: bold;
        }
        
        input[name=resetButton] {
          background-color: #ADADB0;
          margin-top: 15px;
        }
        
    &lt;/style&gt;
    
    
&lt;/head&gt;

&lt;!-- Begin Post --&gt;

&lt;p&gt;On a recent vacation my husband and I happened upon an entertainment shop that was well stocked with board games, dice, playing cards, etc.  We quickly found an item that both of us, absolute nerds that we are, deemed an essential purchase: a book by Boris A. Kordemsky called &lt;a href=&quot;https://www.amazon.com/Moscow-Puzzles-Mathematical-Recreations-Recreational/dp/0486270785/&quot;&gt;The Moscow Puzzles: 359 Mathematical Recreations&lt;/a&gt;.  No, we didn’t spend our entire vacation solving all 359, but we did bring the book home with us and have continued working through them–often over a glass of wine in the evenings.&lt;/p&gt;

&lt;p&gt;One particular puzzle recently caught my attention for several reasons.  I’ll come back to those reasons in a bit, but for now, the problem is called “Down and Up” and it goes like this:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Suppose you have two pencils pressed together and held vertically.  One inch of the pencil on the left, measuring from its lower end, is smeared with paint.  The right pencil is held steady while you slide the left pencil down 1 inch, continuing to press the two pencils together.  You then move the left pencil back up and return it to its former position, all while keeping the two pencils touching.  You continue these actions until you have moved the left pencil down and up 5 times each.  Assume the paint does not dry or run out during this process.  &lt;b&gt;How many inches of each pencil are smeared with paint after your final movement?&lt;/b&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Take a minute to solve this problem before proceeding if you’d like–spoilers ahead!&lt;/p&gt;

&lt;h2 id=&quot;first-thoughts&quot;&gt;First Thoughts&lt;/h2&gt;

&lt;p&gt;When I first heard this problem, I initially thought that perhaps the paint is not smeared to the right pencil at all and perhaps only one inch of paint appears on the left pencil throughout the entire process.  (Did you also expect this?)  But the &lt;em&gt;second&lt;/em&gt; time I read through the problem I started to visualize what might actually be happening.  The solution became much more clear as soon as I tried to make a mental picture of the process.  Since my husband was solving the problem with me, I made him this sketch to share what I was thinking:&lt;/p&gt;

&lt;center&gt;
    &lt;img src=&quot;https://kimfetti.github.io/images/pencil_sketch.png&quot; alt=&quot;Initial ideas as a sketch&quot; width=&quot;550&quot; /&gt;
&lt;/center&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;I managed to distinctly envision the situation, arrive at a solution, and communicate my thought process just with this simple sketch.  For many math puzzles a rough picture provides all you need find the answer, but if my crude drawing hasn’t fully conveyed the solution to you, no worries.  Let’s dive in a bit more methodically with a much nicer illustration.&lt;/p&gt;

&lt;p&gt;&lt;img style=&quot;float: right; padding: 30px;&quot; src=&quot;https://kimfetti.github.io/images/pencil_initial.gif&quot; alt=&quot;Paint is spread to both pencils immediately&quot; width=&quot;500&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;problem-setup&quot;&gt;Problem Setup&lt;/h2&gt;

&lt;p&gt;From the problem directions, we know that initially only the left pencil is smeared with paint.  Recall though that the left pencil presses directly against the right.  This means paint immediately transfers to the right pencil as they are squeezed together.  So both pencils are smeared with one inch of paint even before any of the five down-up movements occur.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;solving-and-illustrating-the-full-problem&quot;&gt;Solving and Illustrating the Full Problem&lt;/h2&gt;

&lt;p&gt;The problem gets a little more complicated as the left pencil moves down and up, but returning to a visual interpretation once again helps immensely.  Also feel free to reread the problem statement at any point to regain your bearings.&lt;/p&gt;

&lt;p&gt;Both pencils are currently smeared with one inch of paint.  Then the left pencil moves down one inch while both pencils continue pressing together.  Can you envision what happens when the left pencil moves down?  Yes!  A clean portion of the left pencil makes contact with the bottom of the right pencil; therefore, another inch of paint transfers over to the left.&lt;/p&gt;

&lt;p&gt;The left pencil now lingers one inch lower than the right.  One inch of the right pencil is smeared with paint, but paint covers &lt;em&gt;two inches&lt;/em&gt; of the left pencil.  The left pencil moves up in the next step of the problem, coming back to its original position.  So the two pencils realign, but what happens to the paint?  Since the left pencil continually makes contact with the right, paint smears over to the right pencil and coats two inches of both pencils at the end of the first down-and-up cycle.&lt;/p&gt;

&lt;p&gt;The four remaining cycles proceed similarly, with paint transferring first to the left pencil and then to the right.  &lt;b&gt;Finally after five rounds of movements, both pencils are smeared with a total of six inches of paint: an initial inch plus five more inches, one for each of the down-up cycles.&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;This problem ultimately hinges on the ability to translate the problem statement into an explanatory visual.  To further contextualize this solution, I created an interactive figure with D3.js.  Below both pencils start with one inch of paint as described in the problem setup. Use the “Move Pencil” button to convince yourself of the answer I provided.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note: these pencils are six fictitious inches long.  After the fifth movement, the pencils reach equilibrium in that paint completely covers them. Hit the “Reset” button at any time to start over.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;div style=&quot;width: 100%; padding-bottom: 15px&quot; id=&quot;pencilContainer&quot;&gt;
    &lt;div style=&quot;float: left; width: 10%; height: 400; padding-left: 5%;&quot;&gt;
        &lt;input name=&quot;paintButton&quot; type=&quot;button&quot; value=&quot;Move Pencil&quot; onclick=&quot;movePencil(); addPaint(1,800); addPaint(2,2000); incrUnits();&quot; /&gt;
        &lt;br /&gt;
        &lt;input name=&quot;resetButton&quot; type=&quot;button&quot; value=&quot;Reset&quot; onclick=&quot;removePaint()&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;script&gt;
var pencilColor = &quot;#F0C446&quot;;
var paintColor = &quot;#271B77&quot;;

var pencilData = [1, 2];

var width = $(&quot;div#pencilContainer&quot;).width();
var height = 400;

var svg = d3.select(&quot;div#pencilContainer&quot;).append(&quot;svg&quot;)
    .attr(&quot;width&quot;, width*.6)
    .attr(&quot;height&quot;, height)
    .style('transform', 'translate(40%, 0%)');

var objects = svg.append(&quot;g&quot;);

var pencils = objects.selectAll(&quot;g&quot;)
  .data(pencilData)
  .enter()
  .append(&quot;g&quot;)
    .attr(&quot;id&quot;, function(d, i) { return i; })
    .attr(&quot;transform&quot;, function(d, i) {return &quot;translate(&quot; + i*50 + &quot;,0)&quot;; });

var rects = pencils.append(&quot;rect&quot;)
    .attr(&quot;x&quot;, 50)
    .attr(&quot;y&quot;, 50)
    .attr(&quot;width&quot;, 50)
    .attr(&quot;height&quot;, 300)
    .attr(&quot;fill&quot;, pencilColor)
    .style(&quot;fill-opacity&quot;, .7)
    .style(&quot;stroke-width&quot;,&quot;.2em&quot;)
    .style(&quot;stroke&quot;, pencilColor);

var triangles = pencils.append(&quot;path&quot;)
    .attr('d', function(d, i) {
        var x = 0, y = 50;
        return 'M ' + (50+x) + ' ' + y + ' l ' + y/2 + ' ' + -y + ' l ' + y/2 + ' ' + y + ' z';
     })
    .attr(&quot;fill&quot;, pencilColor)
    .style(&quot;fill-opacity&quot;, .4)
    .style(&quot;stroke-width&quot;,&quot;.2em&quot;)
    .style(&quot;stroke&quot;, pencilColor);

var tips = pencils.append(&quot;path&quot;)
    .attr('d', function(d, i) {
        var x = 12.5, y = 25;
        return 'M ' + (50+x) + ' ' + y + ' l ' + y/2 + ' ' + -y + ' l ' + y/2 + ' ' + y + ' z';
    })
    .style(&quot;fill-opacity&quot;, .7)
    .style(&quot;stroke-width&quot;,&quot;.2em&quot;)
    .style(&quot;stroke&quot;, &quot;#393731&quot;);

var paint = pencils.append(&quot;rect&quot;)
    .attr(&quot;x&quot;, 50)
    .attr(&quot;y&quot;, 300)
    .attr(&quot;width&quot;, 50)
    .attr(&quot;height&quot;, 50)
    .attr(&quot;fill&quot;, paintColor)
    .style(&quot;fill-opacity&quot;, 0.9)
    .style(&quot;stroke-width&quot;,&quot;.2em&quot;)
    .style(&quot;stroke&quot;, paintColor);

var paintUnits = 1;

var text = svg.append(&quot;text&quot;);

text
  .attr(&quot;x&quot;, 225)
  .attr(&quot;y&quot;, 50)
  .attr(&quot;font-size&quot;,22);

text.append(&quot;tspan&quot;)
  .text(&quot;Paint:&quot;);

var paintText = text.append(&quot;tspan&quot;)
    .attr(&quot;dx&quot;, 10)
    .style(&quot;fill&quot;, paintColor)
    .attr(&quot;font-weight&quot;, &quot;bold&quot;)
    .text(paintUnits + &quot; Inch&quot;);

function movePencil() {
    d3.select(&quot;g&quot;).selectAll(&quot;*&quot;)
      .filter(function (d) { return d == 1; })
      .transition()
        .duration(750)
        .attr(&quot;transform&quot;, &quot;translate(0,25)&quot;)
      .on(&quot;end&quot;,function() {  
          d3.select(this)
            .transition()     
              .delay(750)
              .attr(&quot;transform&quot;, &quot;translate(0,0)&quot;)
      });
}

function addPaint(pencilNumber, delay) {
    d3.select(&quot;g&quot;).selectAll(&quot;*&quot;)
      .filter(function(d) { return d == pencilNumber; })
      .filter(function(d,i) { return i == 4; })
      .transition()
        .delay(delay)
        .attr(&quot;height&quot;, function(d) {
            return Math.min(paintUnits*50 + 50, 300); 
        })
        .attr(&quot;y&quot;, function(d) {
            return Math.max(300 - 50*paintUnits, 50);
        });
}

function incrUnits() {
    paintUnits++;
    paintText.transition()
      .delay(2400)
      .text( Math.min(paintUnits, 6) + &quot; Inches&quot;);
}

function removePaint() {
    paint
      .transition()
      .duration(500)
        .attr(&quot;y&quot;, 300)
        .attr(&quot;height&quot;, 50);

    paintUnits = 1;
    paintText.transition()
      .delay(250)
      .text( paintUnits + &quot; Inch&quot;);
}

&lt;/script&gt;

&lt;h2 id=&quot;backstory-and-problem-extensions&quot;&gt;Backstory and Problem Extensions&lt;/h2&gt;

&lt;p&gt;Earlier I mentioned this problem caught my eye for several reasons.  The first reason is exactly what we have been discussing.  I marveled at how tricky the problem sounds initially as opposed to how simple it becomes as soon as you construct an appropriate mental image of the situation.&lt;/p&gt;

&lt;p&gt;The second reason this puzzle piqued my interest is its history.  As explained in Kordemsky’s book, Leonid Mikhailovich Rybakov, a Soviet mathematician who lived in the early 20th Century, created this “Down and Up” problem.  I deeply appreciate math problems that pervade through many time periods and geographies.  Solving such puzzles allows me to feel more connected to the past and to other mathematicians around the globe.&lt;/p&gt;

&lt;p&gt;Finally, this problem sparked my curiosity because Rybakov first thought it up when returning home from a successful duck hunt.  Kordemsky encourages readers to contemplate why this could be the case but goes on to explain in his “Answers” section.  From &lt;em&gt;The Moscow Puzzles&lt;/em&gt; book:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Looking at his boots, Leonid Mikhailovich noticed that their entire lengths were muddied where they usually rub each other while he walks.&lt;br /&gt;
“How puzzling,” he thought, “I didn’t walk in any deep mud, yet my boots are muddied up to the knees.” &lt;br /&gt;
Now you understand the origin of the puzzle.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Just as the paint smeared the entire length of both pencils, Rybakov’s boots were covered from tip to top because mud had transferred from one boot to the other as he walked.&lt;/p&gt;

&lt;p&gt;I continued to think about how this concept might apply to other situations, and I came up with one amusing but slightly unpleasant example.  Consider two lines of contra dancers in which the first dancer in the first line unfortunately feels unwell.  If this dancer’s sickness is highly communicable, she will, of course, pass along her malady to her dance partner who is positioned across from her.  Sometimes in contra dancing participants exchange dance partners by shifting the two lines laterally.  Regrettably, when this happens the newly infected dancer will pass the disease back across the line, and eventually the entire group of dancers become ill.  Try out my widget below to see this application in action.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;div style=&quot;width: 100%; padding-bottom: 15px&quot; id=&quot;contraContainer&quot;&gt;
    &lt;div style=&quot;float: left; width: 10%; height: 400; padding-left: 5%;&quot;&gt;
        &lt;input name=&quot;danceButton&quot; type=&quot;button&quot; value=&quot;Dance!&quot; onclick=&quot;moveBlushers('left', 0); sickBlusher(); moveBlushers('center', 2500); sickGrinner();&quot; /&gt;
        &lt;br /&gt;
        &lt;input name=&quot;resetButton&quot; type=&quot;button&quot; value=&quot;Reset&quot; onclick=&quot;makeWell()&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;script&gt;

var blushEmoji = &quot;https://kimfetti.github.io/images/emoji_blush.png&quot;;
var grinEmoji = &quot;https://kimfetti.github.io/images/emoji_grin.png&quot;;
var sickEmoji = &quot;https://kimfetti.github.io/images/emoji_sick.png&quot;;

var contraData = [1, 2, 3, 4, 5];

var w = $(&quot;div#contraContainer&quot;).width();
var h = 200;

var canvas = d3.select(&quot;div#contraContainer&quot;).append(&quot;svg&quot;)
    .attr(&quot;width&quot;, w*.75)
    .attr(&quot;height&quot;, h)
    .style('transform', 'translate(30%, 0%)');

var blushGroup = canvas.append(&quot;g&quot;)
    .attr(&quot;id&quot;, &quot;blushers&quot;);

var blushers = blushGroup.selectAll(&quot;image&quot;)
  .data(contraData)
  .enter()
  .append(&quot;image&quot;)
    .attr('xlink:href', function (d, i) {
        if (i == 0) {
          return sickEmoji;
        }
        else {
          return blushEmoji;
        }
    })
    .attr(&quot;x&quot;, function (d, i) { return w/75+d*(w/10); })
    .attr(&quot;y&quot;, 0)
    .attr('width', w/13)
    .attr('height', w/13);
    
var grinGroup = canvas.append(&quot;g&quot;)
    .attr(&quot;id&quot;, &quot;grinners&quot;);

var grinners = grinGroup.selectAll(&quot;image&quot;)
  .data(contraData)
  .enter()
  .append(&quot;image&quot;)
    .attr('xlink:href', grinEmoji)
    .attr(&quot;x&quot;, function (d, i) { return w/75+d*(w/10); })
    .attr(&quot;y&quot;, 100)
    .attr('width', w/14)
    .attr('height', w/14);

var sickNum = 1;

function moveBlushers(pos, delay) {
    if (sickNum == 1) { return; }
    else {
      d3.select(&quot;#blushers&quot;)
        .selectAll(&quot;image&quot;)
        .transition()
        .delay(delay)
        .duration(1000)
          .attr(&quot;transform&quot;, function(d) {
              if (pos==&quot;left&quot;) { return &quot;translate(&quot; + -w/10 +&quot;, 0)&quot;; }
              else if (pos==&quot;center&quot;) { return &quot;translate(0, 0)&quot;; }
          });
    };
}

function sickBlusher() {
    {
        if (sickNum == 1) { return; }
        else { delay = 1200; }
    }
    d3.select(&quot;#blushers&quot;)
      .selectAll(&quot;image&quot;)
      .filter( function (d) { return d == sickNum; })

      .transition()
      .delay(delay)
        .style(&quot;opacity&quot;, 0)
        .attr(&quot;xlink:href&quot;, sickEmoji)

      .transition()
      .duration(800)
        .ease(d3.easeLinear)
        .style(&quot;opacity&quot;, 1);
}

function sickGrinner() {
    {
        if (sickNum == 1) { delay = 300; }
        else { delay = 3300; }
    }
    d3.select(&quot;#grinners&quot;)
      .selectAll(&quot;image&quot;)
      .filter( function (d) { return d == sickNum; })
      .transition()
      .delay(delay)
        .style(&quot;opacity&quot;, 0)
        .on(&quot;end&quot;, function() {  
            d3.select(this)
              .transition()      
              .duration(800)
                .ease(d3.easeLinear)
                .style(&quot;opacity&quot;, 1)
                .attr(&quot;xlink:href&quot;, sickEmoji)
                .attr(&quot;width&quot;, w/13)
                .attr(&quot;height&quot;, w/13)
        });
    sickNum++;
}

function makeWell() {

    d3.select(&quot;#blushers&quot;)
      .selectAll(&quot;image&quot;)
        .attr('xlink:href', function (d, i) {
            if (i == 0) { return sickEmoji; }
            else { return blushEmoji; }
        })
        .attr(&quot;width&quot;, w/13)
        .attr(&quot;height&quot;, w/13);

    d3.select(&quot;#grinners&quot;)
      .selectAll(&quot;image&quot;)
        .attr(&quot;xlink:href&quot;, grinEmoji)
        .attr(&quot;width&quot;, w/14)
        .attr(&quot;height&quot;, w/14);

    sickNum = 1;
}

&lt;/script&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;I hope you have enjoyed this discussion on one of my new favorite math puzzles along with these illustrative D3 visuals.  Making a mental image of a math puzzle is not always easy, but it can be invaluable when solving problems like these–especially if you are a visual learner like myself.  The next time you feel stuck on an interview question, check to see if sketching or imagining the physical setup of the problem helps.  For me it often does.&lt;/p&gt;

&lt;p&gt;I also hope you have enjoyed learning a little about the backstory behind this puzzle.  Some of the world’s best math puzzles were created long ago, so I believe looking to the past when attempting to sharpen our minds benefits us greatly.  Furthermore, expanding this kind of problem to new applications, like I did with the contra dancers, helps solidify core concepts and builds intuition for future brainteasers.  It also makes math problems more enjoyable because you relate them to your own life.  So now it’s your turn – can you think of any other “Down and Up” scenarios?&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Check out my D3 code on GitHub!&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/kimfetti/Blog/blob/master/pencil_paint.html&quot;&gt;Pencils and Paint&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/kimfetti/Blog/blob/master/contra.html&quot;&gt;Contra Dancers&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
</description>
				<guid isPermaLink="true">http://localhost:4000//visualizations/puzzles/down-and-up/</guid>
			</item>
		
			<item>
				<title>How to Gather Data from YouTube</title>
				<link>http://localhost:4000//data/web%20scraping/gather-youtube-data/</link>
				<pubDate>Tue, 12 Nov 2019 00:00:00 -0500</pubDate>
				<description>&lt;p&gt;Since its 2005 inception, YouTube has entertained, educated, and inspired more than &lt;a href=&quot;https://biographon.com/youtube-stats/&quot;&gt;one billion people&lt;/a&gt;.  It now ranks as the &lt;a href=&quot;https://www.alexa.com/siteinfo/youtube.com&quot;&gt;2nd most visited website&lt;/a&gt; on the planet, and its users upload 300 hours of video content every minute.  YouTube clearly dominates as the world’s premier source of &lt;a href=&quot;https://www.youtube.com/watch?v=_OBlgSz8sSM&quot;&gt;cute baby moments&lt;/a&gt;, &lt;a href=&quot;https://www.youtube.com/watch?v=vq8G81oOHhY&quot;&gt;epic sports fails&lt;/a&gt;, and &lt;a href=&quot;https://www.youtube.com/watch?v=AS7_6Uv_Bn0&quot;&gt;hilarious cat videos&lt;/a&gt;, but its vast troves of content can also be leverage to strengthen a wide variety of data science projects.  In this post, I share how you can gain access to three types of YouTube data: the videos themselves for use in computer vision tasks, the video transcripts for natural language processing (NLP), and video search results for hybrid machine learning efforts.&lt;/p&gt;

&lt;p&gt;Please continue to the &lt;a href=&quot;https://www.thisismetis.com/blog/how-to-gather-data-from-youtube&quot;&gt;Metis blog&lt;/a&gt; to read my full post covering data collection from YouTube.&lt;/p&gt;

</description>
				<guid isPermaLink="true">http://localhost:4000//data/web%20scraping/gather-youtube-data/</guid>
			</item>
		
			<item>
				<title>5 Significant Object Detection Challenges and Solutions</title>
				<link>http://localhost:4000//algorithms/literature%20reviews/object-detection-challenges/</link>
				<pubDate>Tue, 10 Sep 2019 00:00:00 -0400</pubDate>
				<description>&lt;!--more--&gt;

&lt;p&gt;The field of computer vision has experienced substantial progress recently owing largely to advances in deep learning, specifically convolutional neural nets (CNNs).  Image classification, where a computer classifies or assigns labels to an image based on its content, can often see great results simply by leveraging pre-trained neural nets and fine-tuning the last few throughput layers.&lt;/p&gt;

&lt;p&gt;Classifying &lt;em&gt;and&lt;/em&gt; finding an unknown number of individual objects within an image, however, was considered an extremely difficult problem only a few years ago.  This task, called object detection, is now feasible and has even been productized by companies like &lt;a href=&quot;https://cloud.google.com/vision/docs/drag-and-drop&quot;&gt;Google&lt;/a&gt; and &lt;a href=&quot;https://www.ibm.com/watson/services/visual-recognition/&quot;&gt;IBM&lt;/a&gt;. But all of this progress wasn’t easy!  Object detection presents many substantial challenges beyond what is required for image classification.  After a brief introduction to  the topic, let’s take a deep dive into several of the interesting obstacles these problems face along with various emerging solutions.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;The ultimate purpose of object detection is to locate important items, draw rectangular bounding boxes around them, and determine the class of each item discovered.  Applications of object detection arise in &lt;a href=&quot;https://www.quora.com/What-are-some-interesting-applications-of-object-detection&quot;&gt;many different fields&lt;/a&gt; including detecting pedestrians for self-driving cars, monitoring agricultural crops, and even real-time ball tracking for sports.  Researchers have dedicated a substantial amount of work towards this goal over the years: from &lt;a href=&quot;https://en.wikipedia.org/wiki/Viola%E2%80%93Jones_object_detection_framework&quot;&gt;Viola and Jones&lt;/a&gt;’s facial detection algorithm published in 2001 to &lt;a href=&quot;https://arxiv.org/abs/1708.02002&quot;&gt;RetinaNet&lt;/a&gt;, a fast, highly accurate one-state detection framework released in 2017.  The introduction of CNNs marks a pivotal moment in object detection history, as nearly all modern systems use CNNs in some form.  That said, the remainder of this post will focus on deep learning solutions for object detection, though similar challenges confront other approaches as well.  To learn more about the basics of object detection, check out my post on the Metis blog: “&lt;a href=&quot;https://www.thisismetis.com/blog/a-beginners-guide-to-object-detection&quot;&gt;A Beginner’s Guide to Object Detection&lt;/a&gt;.”&lt;/p&gt;

&lt;h2 id=&quot;challenges&quot;&gt;Challenges&lt;/h2&gt;

&lt;h3 id=&quot;1-dual-priorities-object-classification-and-localization&quot;&gt;1. Dual priorities: object classification and localization&lt;/h3&gt;

&lt;p&gt;The first major complication of object detection is its added goal: not only do we want to classify image objects but also to determine the objects’ positions, generally referred to as the &lt;em&gt;object localization&lt;/em&gt; task.  To address this issue, researchers most often use a multi-task loss function to penalize both misclassifications and localization errors.&lt;/p&gt;

&lt;p&gt;Regional-based CNNs represent one popular class of object detection frameworks.  These methods consist of the generation of region proposals where objects are likely to be located followed by CNN processing to classify and further refine object locations.  Ross Girshick et al. developed &lt;a href=&quot;https://arxiv.org/pdf/1504.08083.pdf&quot;&gt;Fast R-CNN&lt;/a&gt; to improve upon their initial results with &lt;a href=&quot;https://arxiv.org/pdf/1311.2524.pdf&quot;&gt;R-CNN&lt;/a&gt;. As its name implies, Fast R-CNN provides a dramatic speed-up, but accuracy also improves because the classification and localization tasks are optimized using one unified multi-task loss function.  Each candidate region that may contain an object is compared to the image’s true objects.  Candidate regions then incur penalties for both false classifications and misalignment of the bounding boxes.  Hence, the loss function consists of two kinds of terms:&lt;/p&gt;

&lt;p&gt;\[\mathcal{L}(p, u, t^u, v) = \overbrace{\mathcal{L}_c(p,u)}^{classification} + \lambda\overbrace{\left[u\geq 1\right] \mathcal{L}_l(t^u, v)}^{localization}, \]&lt;/p&gt;

&lt;p&gt;where the classification term imposes log loss on the predicted probability of the true object class \(u\) and the localization term is a smooth \(L_1\) loss for the four positional components that define the rectangle.  Note that the localization penalty does not apply to the background class when no object is present, \(u=0\).  Also note the parameter \(\lambda\) may be adjusted to prioritize either classification or localization more strongly.&lt;/p&gt;

&lt;h3 id=&quot;2-speed-for-real-time-detection&quot;&gt;2. Speed for real-time detection&lt;/h3&gt;

&lt;p&gt;Object detection algorithms need to not only accurately classify and localize important objects, they also need to be incredibly fast at prediction time to meet the real-time demands of video processing.  Several key enhancements over the years have boosted the speed of these algorithms, improving test time from the 0.02 frames per second (fps) of R-CNN to the impressive 155 fps of Fast YOLO.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1504.08083.pdf&quot;&gt;Fast R-CNN&lt;/a&gt; and &lt;a href=&quot;https://arxiv.org/pdf/1506.01497.pdf&quot;&gt;Faster R-CNN&lt;/a&gt; aim to speed up the original R-CNN approach.  R-CNN uses &lt;a href=&quot;https://koen.me/research/pub/uijlings-ijcv2013-draft.pdf&quot;&gt;selective search&lt;/a&gt; to generate 2,000 candidate regions of interest (RoIs) and passes each RoI through a CNN base individually, which causes a massive bottleneck since the CNN processing is quite slow. Fast R-CNN instead sends the entire image through the CNN base just once and then matches the RoIs created with selective search to the CNN feature map, yielding a 20-fold reduction in processing time.  While Fast R-CNN is much speedier than R-CNN, yet another speed barrier persists.  It takes approximately 2.3 seconds for Fast R-CNN to perform object detection on a single image, and selective search accounts for a full 2 seconds of that time!  Faster R-CNN replaces selective search with a separate sub-neural network to generate RoIs, creating another 10x speed up and thus testing at a rate of about 7-18 fps.&lt;/p&gt;

&lt;p&gt;Despite these impressive improvements, videos are typically shot at at least 24 fps, meaning Faster R-CNN will likely not keep pace.  Regional-based methods consist of two separate phases: proposing regions and processing them. This task separation proves to be somewhat inefficient.  Another major type of object detection systems relies on a unified one-state approach instead.  These so-called single-shot detectors fully locate and classify objects during a single pass over the image, which substantially decreases test time.  One such single-shot detector &lt;a href=&quot;https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf&quot;&gt;YOLO&lt;/a&gt; begins by laying out a grid over the image and allows each grid cell to detect a fixed number of objects of varying sizes.  For each true object present in the image, the grid cell associated with the object’s center is responsible for predicting this object.  A complex, multi-term loss function then ensures that all localization and classification occurs within one process.  One version of this method, Fast YOLO, has even achieved rates of 155 fps; however, classification and localization accuracy drops off sharply at this elevated speed.&lt;/p&gt;

&lt;p&gt;Ultimately, today’s object detection algorithms attempt to strike a balance between speed and accuracy.  Several design choices beyond the detection framework influence these outcomes.  For example, &lt;a href=&quot;https://arxiv.org/pdf/1804.02767.pdf&quot;&gt;YOLOv3&lt;/a&gt; allows images of varying resolution: high-res images typically see better accuracy but slower processing times and vice versa for low-res images.  The choice of the CNN base also affects the speed-accuracy tradeoff.  Very deep networks like the 164 layers used in Inception-ResNet-V2 yield impressive accuracy, but pale in comparison to frameworks with VGG-16 in terms of speed.  Object detection design choices must be made in context depending on whether speed or accuracy takes priority.&lt;/p&gt;

&lt;h3 id=&quot;3-multiple-spatial-scales-and-aspect-ratios&quot;&gt;3. Multiple spatial scales and aspect ratios&lt;/h3&gt;

&lt;p&gt;For many applications of object detection, items of interest may appear in a wide range of sizes and aspect ratios.  Practitioners leverage several techniques to ensure detection algorithms are able to capture objects at multiple scales and views.&lt;/p&gt;

&lt;h4 id=&quot;anchor-boxes&quot;&gt;Anchor boxes&lt;/h4&gt;

&lt;p&gt;Instead of selective search, Faster R-CNN’s updated region proposal network uses a small sliding window across the image’s convolutional feature map to generate candidate RoIs.  Multiple RoIs may be predicted at each position and are described relative to reference &lt;em&gt;anchor boxes&lt;/em&gt;.  The shapes and sizes of these anchor boxes are carefully chosen to span a range of different scales and aspect ratios.  This allows various types of objects to be detected with the hopes that the bounding box coordinates need not be adjusted much during the localization task.  Other frameworks, including single-shot detectors, also adopt anchor boxes to initialize regions of interest.&lt;/p&gt;

&lt;center&gt;
&lt;img src=&quot;https://kimfetti.github.io/images/anchors.png&quot; alt=&quot;Anchor boxes&quot; width=&quot;500&quot; /&gt;
&lt;p&gt;&lt;em&gt; Carefully chosen anchor boxes of varying sizes and aspect ratios help create diverse regions of interest.&lt;/em&gt;&lt;/p&gt;
&lt;/center&gt;

&lt;h4 id=&quot;multiple-feature-maps&quot;&gt;Multiple feature maps&lt;/h4&gt;

&lt;p&gt;Single-shot detectors must place special emphasis on the issue of multiple scales because they detect objects with a single pass through the CNN framework.  If objects are detected from the final CNN layers alone, only large items will be found as smaller items may lose too much signal during downsampling in the pooling layers.  To address this problem, single-shot detectors typically look for objects within multiple CNN layers including earlier layers where higher resolution remains.  Despite the precaution of using multiple feature maps, single-shot detectors notoriously struggle to detect small objects, especially those in tight groupings like a flock of birds.&lt;/p&gt;

&lt;center&gt;
&lt;img src=&quot;https://kimfetti.github.io/images/ssd.png&quot; alt=&quot;SSD with multiple feature maps&quot; width=&quot;800&quot; /&gt;
&lt;p&gt;&lt;em&gt; Feature maps from multiple CNN layers help predict objects at multiple scales.&lt;/em&gt;&lt;/p&gt;
&lt;/center&gt;

&lt;h4 id=&quot;feature-pyramid-network&quot;&gt;Feature pyramid network&lt;/h4&gt;

&lt;p&gt;The &lt;a href=&quot;https://arxiv.org/pdf/1612.03144.pdf&quot;&gt;feature pyramid network (FPN)&lt;/a&gt; takes the concept of multiple feature maps one step further.  Images first pass through the typical CNN pathway, yielding semantically rich final layers.  Then to regain better resolution, FPN creates a top-down pathway by upsampling this feature map.  While the top-down pathway helps detect objects of varying sizes, spatial positions may be skewed.  Lateral connections are added between the original feature maps and the corresponding reconstructed layers to improve object localization.  FPN currently provides one of the leading ways to detect objects at multiple scales, and YOLO was augmented with this technique in &lt;a href=&quot;https://arxiv.org/pdf/1804.02767.pdf&quot;&gt;its 3rd version&lt;/a&gt;.&lt;/p&gt;

&lt;center&gt;
&lt;img src=&quot;https://kimfetti.github.io/images/fpn.png&quot; alt=&quot;Feature pyramid network&quot; width=&quot;450&quot; /&gt;
&lt;p&gt;&lt;em&gt; The feature pyramid network detects objects of varying sizes by reconstructing high resolution layers from layers with greater semantic strength.&lt;/em&gt;&lt;/p&gt;
&lt;/center&gt;

&lt;h3 id=&quot;4-limited-data&quot;&gt;4. Limited data&lt;/h3&gt;

&lt;p&gt;The limited amount of annotated data currently available for object detection proves to be another substantial hurdle.  Object detection datasets typically contain ground truth examples for about a dozen to a hundred classes of objects, while image classification datasets can include upwards of 100,000 classes.  Furthermore, crowd sourcing often produces image classification tags for free (for example, by parsing the text of user-provided photo captions).  Gathering ground truth labels &lt;em&gt;along with&lt;/em&gt; accurate bounding boxes for object detection, however, remains incredibly tedious work.&lt;/p&gt;

&lt;p&gt;The COCO dataset, provided by Microsoft, currently leads as some of the best object detection data available.  COCO contains 300,000 segmented images with &lt;a href=&quot;https://github.com/pjreddie/darknet/blob/master/data/coco.names&quot;&gt;80 different categories&lt;/a&gt; of objects with very precise location labels.  Each image contains about 7 objects on average, and items appear at very broad scales.  As helpful as this dataset is, object types outside of these 80 select classes will not be recognized if training solely on COCO.&lt;/p&gt;

&lt;p&gt;A very interesting approach to alleviate data scarcity comes from YOLO9000, the &lt;a href=&quot;https://arxiv.org/pdf/1612.08242.pdf&quot;&gt;second version of YOLO&lt;/a&gt;.  YOLO9000 incorporates many important updates into YOLO, but it also aims to narrow the dataset gap between object detection and image classification.  YOLO9000 trains simultaneously on both COCO and &lt;a href=&quot;http://www.image-net.org/&quot;&gt;ImageNet&lt;/a&gt;, an image classification dataset with tens of thousands of object classes.  COCO information helps precisely locate objects, while ImageNet increases YOLO’s classification “vocabulary.”  A hierarchical WordTree allows YOLO9000 to first detect an object’s concept (such as “animal/dog”) and to then drill down into specifics (such as “Siberian husky”).  This approach appears to work well for concepts known to COCO like animals but performs poorly on less prevalent concepts since RoI suggestion comes solely from the training with COCO.&lt;/p&gt;

&lt;center&gt;
&lt;img src=&quot;https://kimfetti.github.io/images/yolo9000.png&quot; alt=&quot;YOLO9000 WordTree and examples&quot; width=&quot;700&quot; /&gt;
&lt;p&gt;&lt;em&gt; YOLO9000 trains on both COCO and ImageNet to increase classification &quot;vocabulary.&quot;&lt;/em&gt;&lt;/p&gt;
&lt;/center&gt;

&lt;h3 id=&quot;5-class-imbalance&quot;&gt;5. Class imbalance&lt;/h3&gt;

&lt;p&gt;Class imbalance proves to be an issue for most classification problems, and object detection is no exception.  Consider a typical photograph.  More likely than not, the photograph contains a few main objects and the remainder of the image is filled with background.  Recall that selective search in R-CNN produces 2,000 candidate RoIs per image–just imagine how many of these regions do not contain objects and are considered negatives!&lt;/p&gt;

&lt;p&gt;A recent approach called focal loss is implemented in &lt;a href=&quot;https://arxiv.org/abs/1708.02002&quot;&gt;RetinaNet&lt;/a&gt; and helps diminish the impact of class imbalance.  In the optimization loss function, focal loss replaces the traditional log loss when penalizing misclassifications:
\[ FL(p_u) = -\overbrace{(1-p_u)^\gamma\;}^{*} \log(p_u)\]
where \(p_u \) is the predicted class probability for the true class and \(\gamma &amp;gt; 0\).  The additional factor (*) reduces loss for well-classified examples with high probabilities, and the overall effect de-emphasizes classes with many examples that the model knows well, such as the background class.  Objects of interest occupying minority classes, therefore, receive more significance and see improved accuracy.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Object detection is customarily considered to be much harder than image classification, particularly because of these five challenges: dual priorities, speed, multiple scales, limited data, and class imbalance.  Researchers have dedicated much effort to overcome these difficulties, yielding oftentimes amazing results; however, significant challenges still persist.&lt;/p&gt;

&lt;p&gt;Basically all object detection frameworks continue to struggle with small objects, especially those bunched together with partial occlusions.  Real-time detection with top-level classification and localization accuracy remains challenging, and practitioners must often prioritize one or the other when making design decisions.  Video tracking may see improvements in the future if some continuity between frames is assumed rather than processing each frame individually.  Furthermore, an interesting enhancement that may see more exploration would extend the current two-dimensional bounding boxes into three-dimensional bounding cubes.  Even though many object detection obstacles have seen creative solutions, these additional considerations–and plenty more–signal that object detection research is certainly not done!&lt;/p&gt;

</description>
				<guid isPermaLink="true">http://localhost:4000//algorithms/literature%20reviews/object-detection-challenges/</guid>
			</item>
		
	</channel>
</rss>
